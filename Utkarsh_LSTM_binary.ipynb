{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Utkarsh_LSTM_binary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNX/qx0Lm5zXL6zCi7VSj+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarshsharma1/ECG_Signals/blob/master/Utkarsh_LSTM_binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81FnSr3r1GPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "ef092386-c5b2-484c-9ddd-41f6524c8060"
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 62kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.1)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.27.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.17.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (45.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPisH3tU1W5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvKrZtR-1Znr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "adeaf822-f07c-4307-b237-c7f79554c818"
      },
      "source": [
        "!pip install wfdb\n",
        "import wfdb              # much needed for annotations"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/96/c2200539fdf4f087e14d30ed62a66544b6f441196bcb8ecc7a29ec6503b9/wfdb-2.2.1.tar.gz (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.2MB/s \n",
            "\u001b[?25hCollecting nose>=1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 26.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40kB 35.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51kB 36.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61kB 38.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71kB 39.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92kB 42.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.17.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.1.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.4.6)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->wfdb) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->wfdb) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn>=0.0->wfdb) (0.22.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->wfdb) (45.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->wfdb) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn>=0.0->wfdb) (0.14.1)\n",
            "Building wheels for collected packages: wfdb\n",
            "  Building wheel for wfdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wfdb: filename=wfdb-2.2.1-cp36-none-any.whl size=100368 sha256=3b2429c824afb1d7e7cb456429d66cceacd3bf5ad59407af7134291529b32887\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a9/00/0078d26b0c15b31be0001af8eb659496709c361c69641303f1\n",
            "Successfully built wfdb\n",
            "Installing collected packages: nose, wfdb\n",
            "Successfully installed nose-1.3.7 wfdb-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td0oGXFD1bx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'mit-bih-arrhythmia-database-1.0.0/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITY3bJkb1eTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_database = ['100', '101', '102', '103', '104', '105', '106', '107', '108', \n",
        "                   '109', '111', '112', '113', '114', '115', '116', '117', '118',\n",
        "                   '119', '121', '122', '123', '124', '200', '201', '202', '203',\n",
        "                   '205', '207', '208', '209', '210', '212', '213', '214', '215',\n",
        "                   '217', '219', '220', '221', '222', '223', '228', '230', '231',\n",
        "                   '232', '233', '234']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJE42Ife1gFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_ecg_signal(file):\n",
        "    \n",
        "    record = wfdb.rdrecord(file, pb_dir= 'mitdb')\n",
        "    annotation = wfdb.rdann(file, 'atr', pb_dir= 'mitdb')\n",
        "    \n",
        "    #This gives signal\n",
        "    p_signal = record.p_signal\n",
        "    \n",
        "    assert record.fs == 360, 'Sample frequency is not 360'\n",
        "    \n",
        "    #This gives symbols & annotation index\n",
        "    atr_symbol = annotation.symbol\n",
        "    atr_sample = annotation.sample\n",
        "    \n",
        "    return p_signal, atr_symbol, atr_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lDmw_w1iUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abnormal = ['L', 'R', 'V', '/', 'A', 'f', 'F', 'j', 'a', 'E', 'J', 'e', 'S']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XiJxbem1kWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(sample_database, no_of_sec, fs):\n",
        "    \n",
        "    #No of columns\n",
        "    num_cols = 2 * no_of_sec * fs\n",
        "    X_all = np.zeros((1, num_cols))\n",
        "    Y_all = np.zeros((1,1))\n",
        "    symbol_all = []\n",
        "    \n",
        "    max_rows = []\n",
        "    \n",
        "    for i in sample_database:\n",
        "        #file = path + i\n",
        "        print(i)\n",
        "        p_signal, atr_symbol, atr_sample = load_ecg_signal(i)\n",
        "        \n",
        "        #Take out first signal as there are 2 signals\n",
        "        p_signal = p_signal[:,0]\n",
        "        \n",
        "        #Make a dataframe to exclude irrevalent atr_symbol\n",
        "        #atr_sample is index of annotation\n",
        "        df_annotation = pd.DataFrame({'atr_symbol': atr_symbol,'atr_sample': atr_sample})\n",
        "        df_annotation = df_annotation.loc[df_annotation.atr_symbol.isin(abnormal + ['N'])]\n",
        "        \n",
        "        #Gives no of accepted pulses\n",
        "        no_of_rows = len(df_annotation)\n",
        "        \n",
        "        #creates matrix accordingly\n",
        "        X = np.zeros((no_of_rows, num_cols))\n",
        "        Y = np.zeros((no_of_rows, 1))\n",
        "        \n",
        "        #keep track of rows\n",
        "        row_number = 0\n",
        "        \n",
        "        #Now iterate through the dataframe\n",
        "        for atr_sample, atr_symbol in zip(df_annotation.atr_sample.values, df_annotation.atr_symbol.values):\n",
        "            \n",
        "            #Took min and max value in order to tackle the 2 extreme end cases\n",
        "            left = max([0, (atr_sample - no_of_sec * fs)])\n",
        "            right = min([len(p_signal), (atr_sample + no_of_sec * fs)])\n",
        "            x = p_signal[left: right]\n",
        "            \n",
        "            if len(x) == num_cols:\n",
        "            \n",
        "                #This will store all the values of p_signal from 'left' to 'right'\n",
        "                X[row_number, :] = x\n",
        "                \n",
        "                #This line will store 0 if its normal & 1 if its abnormal in Y\n",
        "                Y[row_number, :] = int(atr_symbol in abnormal)\n",
        "                \n",
        "                #A list consisting of all symbols\n",
        "                symbol_all.append(atr_symbol)\n",
        "                row_number += 1\n",
        "                \n",
        "        #Reduces rows of X and Y as we remove some datas whose len(x) != num_cols\n",
        "        X = X[: row_number, :]\n",
        "        Y = Y[: row_number, :]\n",
        "                \n",
        "        #For checking dimensions       \n",
        "        max_rows.append(row_number)\n",
        "                \n",
        "        #append X and Y from previous iteration with new data\n",
        "        X_all = np.append(X_all, X, axis = 0)\n",
        "        Y_all = np.append(Y_all, Y, axis = 0)\n",
        "     \n",
        "    #Removes first column as it contains only zeros when we initialized it\n",
        "    X_all = X_all[1:, :]\n",
        "    Y_all = Y_all[1:, :]\n",
        "            \n",
        "    \n",
        "    assert np.sum(max_rows) == X_all.shape[0], 'No of rows messed 1'\n",
        "    assert Y_all.shape[0] == X_all.shape[0], 'No of rows messed 2' \n",
        "    assert Y_all.shape[0] == len(symbol_all), 'No of rows messed 3'\n",
        "            \n",
        "    return X_all, Y_all, symbol_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBPvvLV61mvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "def calc_prevalence(Y_actual):\n",
        "  return sum(Y_actual)/ len(Y_actual)\n",
        "\n",
        "def calc_specificity(Y_actual, Y_pred, thresh):\n",
        "  return sum((Y_pred < thresh) & (Y_actual == 0))/ sum(Y_actual == 0)\n",
        "\n",
        "def print_report(Y_actual, Y_pred, thresh):\n",
        "\n",
        "  auc = roc_auc_score(Y_actual, Y_pred)\n",
        "  accuracy = accuracy_score(Y_actual, (Y_pred > thresh))\n",
        "  recall = recall_score(Y_actual, (Y_pred > thresh))\n",
        "  precision = precision_score(Y_actual, (Y_pred > thresh))\n",
        "  specificity = calc_specificity(Y_actual, Y_pred, thresh)\n",
        "  prevalence = calc_prevalence(Y_actual)\n",
        "  print('AUC: %.3f' %auc)\n",
        "  print('Accuracy: %.3f' %accuracy)\n",
        "  print('Recall: %.3f' %recall)\n",
        "  print('Precision: %.3f' %precision)\n",
        "  print('Specificity: %.3f' %specificity)\n",
        "  print('Prevalence: %.3f' %prevalence)\n",
        "  print('')\n",
        "  return auc, accuracy, recall, precision, specificity\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYUV3GHK1pG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e06f4fb2-0c05-45f8-c0dd-94c5a91e9c91"
      },
      "source": [
        "#Technically the same patient can show up in both the training and validation sets. \n",
        "#This means that we may have accidentally leaked information across the datasets. \n",
        "#We can test this idea by splitting on patients instead of samples.\n",
        "import random\n",
        "random.seed(27)\n",
        "\n",
        "pts_train = random.sample(sample_database, 36)\n",
        "pts_valid = [pt for pt in sample_database if pt not in pts_train]\n",
        "print(len(pts_train), len(pts_valid))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ijKVBB12Km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "outputId": "8a7d9b3c-10c6-485d-ab5a-26fd15aeb3ae"
      },
      "source": [
        "#Lets keep no_of_sec as -+ of 3\n",
        "no_of_sec = 3\n",
        "#sampling frequency is 360\n",
        "fs = 360\n",
        "\n",
        "X_train, Y_train, Sym_train = make_dataset(pts_train, no_of_sec, fs)\n",
        "X_valid, Y_valid, Sym_valid = make_dataset(pts_valid, no_of_sec, fs)\n",
        "print(X_train.shape, Y_train.shape, len(Sym_train))\n",
        "print(X_valid.shape, Y_valid.shape, len(Sym_valid))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "223\n",
            "209\n",
            "231\n",
            "118\n",
            "119\n",
            "113\n",
            "104\n",
            "234\n",
            "117\n",
            "214\n",
            "123\n",
            "221\n",
            "200\n",
            "202\n",
            "112\n",
            "116\n",
            "212\n",
            "210\n",
            "203\n",
            "102\n",
            "215\n",
            "122\n",
            "230\n",
            "208\n",
            "207\n",
            "121\n",
            "114\n",
            "219\n",
            "101\n",
            "115\n",
            "213\n",
            "100\n",
            "233\n",
            "222\n",
            "205\n",
            "109\n",
            "103\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "111\n",
            "124\n",
            "201\n",
            "217\n",
            "220\n",
            "228\n",
            "232\n",
            "(84802, 2160) (84802, 1) 84802\n",
            "(24297, 2160) (24297, 1) 24297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g81AAV922Dil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFDTjMH6px3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ad30e1d3-9ecb-4c0e-d7cf-f8febd9f5eae"
      },
      "source": [
        "X_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n",
        "\n",
        "print(X_train_cnn.shape)\n",
        "print(X_valid_cnn.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(84802, 2160, 1)\n",
            "(24297, 2160, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG7nYMD42QuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(64, input_shape = (X_train_cnn.shape[1], X_train_cnn.shape[2]))))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKWbL1VK50a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-idYhnFC5-7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "204cdc44-5e35-4e8b-9b02-008d6b1f21c8"
      },
      "source": [
        "model.fit(X_train_cnn, Y_train, batch_size = 32, epochs = 2, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 84802 samples\n",
            "Epoch 1/2\n",
            "10976/84802 [==>...........................] - ETA: 1:08:34 - loss: 0.5837 - accuracy: 0.7291"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JCnLCAY6CAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train_preds_lstm = model.predict_proba(X_train_cnn, verbose = 1)\n",
        "Y_valid_preds_lstm = model.predict_proba(X_valid_cnn, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSmbaFiQ6OSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It calculates the ratio of number of values of Y_train = 0 to size of Y_train\n",
        "thresh = (sum(Y_train)/ len(Y_train))[0]\n",
        "thresh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbEm5RJU6Qxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train');\n",
        "print_report(Y_train, Y_train_preds_cnn, thresh)\n",
        "print('Valid');\n",
        "print_report(Y_valid, Y_valid_preds_cnn, thresh)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}