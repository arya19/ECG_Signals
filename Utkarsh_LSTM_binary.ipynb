{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Utkarsh_LSTM_binary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RaeMnFbwF-QMjL0yv6tUe79zDXbWdBwd",
      "authorship_tag": "ABX9TyOVbJg002F0ilmeojyAZXF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarshsharma1/ECG_Signals/blob/master/Utkarsh_LSTM_binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSkli8yWi9TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18558f8d-d052-45e9-d670-4aa43a9828bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81FnSr3r1GPE",
        "colab_type": "code",
        "outputId": "3ef2996c-dca6-488a-f954-6c703270b821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (2.10.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from h5py) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /tensorflow-2.1.0/python3.6 (from h5py) (1.18.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPisH3tU1W5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvKrZtR-1Znr",
        "colab_type": "code",
        "outputId": "6b76f32e-975d-441c-d02b-5e444550174d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install wfdb\n",
        "import wfdb              # much needed for annotations"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/96/c2200539fdf4f087e14d30ed62a66544b6f441196bcb8ecc7a29ec6503b9/wfdb-2.2.1.tar.gz (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 31.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 35.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 39.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 38.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 40.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 30.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 32.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 33.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n",
            "\u001b[?25hCollecting nose>=1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30kB 35.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40kB 39.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51kB 39.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61kB 40.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81kB 42.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92kB 44.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112kB 41.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133kB 41.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153kB 41.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /tensorflow-2.1.0/python3.6 (from wfdb) (1.18.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (3.1.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /tensorflow-2.1.0/python3.6 (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /tensorflow-2.1.0/python3.6 (from wfdb) (1.4.1)\n",
            "Requirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from wfdb) (0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->wfdb) (2.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.10.0->wfdb) (2019.11.28)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.10.0->wfdb) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.10.0->wfdb) (1.25.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.10.0->wfdb) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->wfdb) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn>=0.0->wfdb) (0.22.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from cycler>=0.10->matplotlib>=1.5.1->wfdb) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from kiwisolver>=1.0.1->matplotlib>=1.5.1->wfdb) (45.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn>=0.0->wfdb) (0.14.1)\n",
            "Building wheels for collected packages: wfdb\n",
            "  Building wheel for wfdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wfdb: filename=wfdb-2.2.1-cp36-none-any.whl size=100368 sha256=29762a6b3891c567723967fe8ecb1e571c26bfdb652afaee063eed2cea38f4b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a9/00/0078d26b0c15b31be0001af8eb659496709c361c69641303f1\n",
            "Successfully built wfdb\n",
            "Installing collected packages: nose, wfdb\n",
            "Successfully installed nose-1.3.7 wfdb-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td0oGXFD1bx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'mit-bih-arrhythmia-database-1.0.0/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITY3bJkb1eTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_database = ['100', '101', '102', '103', '104', '105', '106', '107', '108', \n",
        "                   '109', '111', '112', '113', '114', '115', '116', '117', '118',\n",
        "                   '119', '121', '122', '123', '124', '200', '201', '202', '203',\n",
        "                   '205', '207', '208', '209', '210', '212', '213', '214', '215',\n",
        "                   '217', '219', '220', '221', '222', '223', '228', '230', '231',\n",
        "                   '232', '233', '234']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJE42Ife1gFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_ecg_signal(file):\n",
        "    \n",
        "    record = wfdb.rdrecord(file, pb_dir= 'mitdb')\n",
        "    annotation = wfdb.rdann(file, 'atr', pb_dir= 'mitdb')\n",
        "    \n",
        "    #This gives signal\n",
        "    p_signal = record.p_signal\n",
        "    \n",
        "    assert record.fs == 360, 'Sample frequency is not 360'\n",
        "    \n",
        "    #This gives symbols & annotation index\n",
        "    atr_symbol = annotation.symbol\n",
        "    atr_sample = annotation.sample\n",
        "    \n",
        "    return p_signal, atr_symbol, atr_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lDmw_w1iUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abnormal = ['L', 'R', 'V', '/', 'A', 'f', 'F', 'j', 'a', 'E', 'J', 'e', 'S']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XiJxbem1kWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(sample_database, no_of_sec, fs):\n",
        "    \n",
        "    #No of columns\n",
        "    num_cols = 2 * no_of_sec * fs\n",
        "    X_all = np.zeros((1, num_cols))\n",
        "    Y_all = np.zeros((1,1))\n",
        "    symbol_all = []\n",
        "    \n",
        "    max_rows = []\n",
        "    \n",
        "    for i in sample_database:\n",
        "        #file = path + i\n",
        "        print(i)\n",
        "        p_signal, atr_symbol, atr_sample = load_ecg_signal(i)\n",
        "        \n",
        "        #Take out first signal as there are 2 signals\n",
        "        p_signal = p_signal[:,0]\n",
        "        \n",
        "        #Make a dataframe to exclude irrevalent atr_symbol\n",
        "        #atr_sample is index of annotation\n",
        "        df_annotation = pd.DataFrame({'atr_symbol': atr_symbol,'atr_sample': atr_sample})\n",
        "        df_annotation = df_annotation.loc[df_annotation.atr_symbol.isin(abnormal + ['N'])]\n",
        "        \n",
        "        #Gives no of accepted pulses\n",
        "        no_of_rows = len(df_annotation)\n",
        "        \n",
        "        #creates matrix accordingly\n",
        "        X = np.zeros((no_of_rows, num_cols))\n",
        "        Y = np.zeros((no_of_rows, 1))\n",
        "        \n",
        "        #keep track of rows\n",
        "        row_number = 0\n",
        "        \n",
        "        #Now iterate through the dataframe\n",
        "        for atr_sample, atr_symbol in zip(df_annotation.atr_sample.values, df_annotation.atr_symbol.values):\n",
        "            \n",
        "            #Took min and max value in order to tackle the 2 extreme end cases\n",
        "            left = max([0, (atr_sample - no_of_sec * fs)])\n",
        "            right = min([len(p_signal), (atr_sample + no_of_sec * fs)])\n",
        "            x = p_signal[left: right]\n",
        "            \n",
        "            if len(x) == num_cols:\n",
        "            \n",
        "                #This will store all the values of p_signal from 'left' to 'right'\n",
        "                X[row_number, :] = x\n",
        "                \n",
        "                #This line will store 0 if its normal & 1 if its abnormal in Y\n",
        "                Y[row_number, :] = int(atr_symbol in abnormal)\n",
        "                \n",
        "                #A list consisting of all symbols\n",
        "                symbol_all.append(atr_symbol)\n",
        "                row_number += 1\n",
        "                \n",
        "        #Reduces rows of X and Y as we remove some datas whose len(x) != num_cols\n",
        "        X = X[: row_number, :]\n",
        "        Y = Y[: row_number, :]\n",
        "                \n",
        "        #For checking dimensions       \n",
        "        max_rows.append(row_number)\n",
        "                \n",
        "        #append X and Y from previous iteration with new data\n",
        "        X_all = np.append(X_all, X, axis = 0)\n",
        "        Y_all = np.append(Y_all, Y, axis = 0)\n",
        "     \n",
        "    #Removes first column as it contains only zeros when we initialized it\n",
        "    X_all = X_all[1:, :]\n",
        "    Y_all = Y_all[1:, :]\n",
        "            \n",
        "    \n",
        "    assert np.sum(max_rows) == X_all.shape[0], 'No of rows messed 1'\n",
        "    assert Y_all.shape[0] == X_all.shape[0], 'No of rows messed 2' \n",
        "    assert Y_all.shape[0] == len(symbol_all), 'No of rows messed 3'\n",
        "            \n",
        "    return X_all, Y_all, symbol_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBPvvLV61mvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "def calc_prevalence(Y_actual):\n",
        "  return sum(Y_actual)/ len(Y_actual)\n",
        "\n",
        "def calc_specificity(Y_actual, Y_pred, thresh):\n",
        "  return sum((Y_pred < thresh) & (Y_actual == 0))/ sum(Y_actual == 0)\n",
        "\n",
        "def print_report(Y_actual, Y_pred, thresh):\n",
        "\n",
        "  auc = roc_auc_score(Y_actual, Y_pred)\n",
        "  accuracy = accuracy_score(Y_actual, (Y_pred > thresh))\n",
        "  recall = recall_score(Y_actual, (Y_pred > thresh))\n",
        "  precision = precision_score(Y_actual, (Y_pred > thresh))\n",
        "  specificity = calc_specificity(Y_actual, Y_pred, thresh)\n",
        "  prevalence = calc_prevalence(Y_actual)\n",
        "  print('AUC: %.3f' %auc)\n",
        "  print('Accuracy: %.3f' %accuracy)\n",
        "  print('Recall: %.3f' %recall)\n",
        "  print('Precision: %.3f' %precision)\n",
        "  print('Specificity: %.3f' %specificity)\n",
        "  print('Prevalence: %.3f' %prevalence)\n",
        "  print('')\n",
        "  return auc, accuracy, recall, precision, specificity\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYUV3GHK1pG5",
        "colab_type": "code",
        "outputId": "21b55038-30af-40e8-9fb0-61cf3f0cc5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Technically the same patient can show up in both the training and validation sets. \n",
        "#This means that we may have accidentally leaked information across the datasets. \n",
        "#We can test this idea by splitting on patients instead of samples.\n",
        "import random\n",
        "random.seed(27)\n",
        "\n",
        "pts_train = random.sample(sample_database, 36)\n",
        "pts_valid = [pt for pt in sample_database if pt not in pts_train]\n",
        "print(len(pts_train), len(pts_valid))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ijKVBB12Km",
        "colab_type": "code",
        "outputId": "2ef03609-29b8-4775-f19d-ac99b7851c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "#Lets keep no_of_sec as -+ of 3\n",
        "no_of_sec = 3\n",
        "#sampling frequency is 360\n",
        "fs = 360\n",
        "\n",
        "X_train, Y_train, Sym_train = make_dataset(pts_train, no_of_sec, fs)\n",
        "X_valid, Y_valid, Sym_valid = make_dataset(pts_valid, no_of_sec, fs)\n",
        "print(X_train.shape, Y_train.shape, len(Sym_train))\n",
        "print(X_valid.shape, Y_valid.shape, len(Sym_valid))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "223\n",
            "209\n",
            "231\n",
            "118\n",
            "119\n",
            "113\n",
            "104\n",
            "234\n",
            "117\n",
            "214\n",
            "123\n",
            "221\n",
            "200\n",
            "202\n",
            "112\n",
            "116\n",
            "212\n",
            "210\n",
            "203\n",
            "102\n",
            "215\n",
            "122\n",
            "230\n",
            "208\n",
            "207\n",
            "121\n",
            "114\n",
            "219\n",
            "101\n",
            "115\n",
            "213\n",
            "100\n",
            "233\n",
            "222\n",
            "205\n",
            "109\n",
            "103\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "111\n",
            "124\n",
            "201\n",
            "217\n",
            "220\n",
            "228\n",
            "232\n",
            "(84802, 2160) (84802, 1) 84802\n",
            "(24297, 2160) (24297, 1) 24297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g81AAV922Dil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFDTjMH6px3",
        "colab_type": "code",
        "outputId": "32900b6e-cf65-40cb-9995-d3da762482fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n",
        "\n",
        "print(X_train_cnn.shape)\n",
        "print(X_valid_cnn.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(84802, 2160, 1)\n",
            "(24297, 2160, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG7nYMD42QuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(64, input_shape = (X_train_cnn.shape[1], X_train_cnn.shape[2]))))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKWbL1VK50a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDWoNugLckxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/training_lstm/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-idYhnFC5-7S",
        "colab_type": "code",
        "outputId": "ebd8f5fb-52b8-4090-cccf-070f948f9ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.fit(X_train_cnn, Y_train, \n",
        "          batch_size = 32, \n",
        "          epochs = 2, \n",
        "          validation_data=(X_valid_cnn, Y_valid),\n",
        "          callbacks=[cp_callback], \n",
        "          verbose = 1)\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored.\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 84802 samples, validate on 24297 samples\n",
            "Epoch 1/2\n",
            "84800/84802 [============================>.] - ETA: 0s - loss: 0.5880 - accuracy: 0.7243\n",
            "Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/training_lstm/cp.ckpt\n",
            "84802/84802 [==============================] - 464s 5ms/sample - loss: 0.5880 - accuracy: 0.7243 - val_loss: 0.7579 - val_accuracy: 0.5483\n",
            "Epoch 2/2\n",
            "84800/84802 [============================>.] - ETA: 0s - loss: 0.5860 - accuracy: 0.7249\n",
            "Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/training_lstm/cp.ckpt\n",
            "84802/84802 [==============================] - 505s 6ms/sample - loss: 0.5860 - accuracy: 0.7249 - val_loss: 0.7565 - val_accuracy: 0.5483\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional multiple                  33792     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  129       \n",
            "=================================================================\n",
            "Total params: 33,921\n",
            "Trainable params: 33,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlrZhoFbiwLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/training_lstm/lstm_v1.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JCnLCAY6CAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2ba3018c-fb1f-4540-8e19-4f2e66e63fa8"
      },
      "source": [
        "Y_train_preds_lstm = model.predict_proba(X_train_cnn, verbose = 1)\n",
        "Y_valid_preds_lstm = model.predict_proba(X_valid_cnn, verbose = 1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84802/84802 [==============================] - 186s 2ms/sample\n",
            "24297/24297 [==============================] - 53s 2ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSmbaFiQ6OSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "458cc645-7701-403f-91c3-c78b39c505be"
      },
      "source": [
        "#It calculates the ratio of number of values of Y_train = 0 to size of Y_train\n",
        "thresh = (sum(Y_train)/ len(Y_train))[0]\n",
        "thresh"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2750878517016108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbEm5RJU6Qxr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c2557dad-68bf-40b9-f0b2-2942a3668e96"
      },
      "source": [
        "print('Train');\n",
        "print_report(Y_train, Y_train_preds_lstm, thresh)\n",
        "print('Valid');\n",
        "print_report(Y_valid, Y_valid_preds_lstm, thresh)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "AUC: 0.547\n",
            "Accuracy: 0.437\n",
            "Recall: 0.734\n",
            "Precision: 0.292\n",
            "Specificity: 0.325\n",
            "Prevalence: 0.275\n",
            "\n",
            "Valid\n",
            "AUC: 0.547\n",
            "Accuracy: 0.452\n",
            "Recall: 0.784\n",
            "Precision: 0.440\n",
            "Specificity: 0.179\n",
            "Prevalence: 0.452\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5468801603400055,\n",
              " 0.4520311149524633,\n",
              " 0.7835276967930029,\n",
              " 0.44016787798136964,\n",
              " array([0.17889047]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkGbSHGPCQU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}